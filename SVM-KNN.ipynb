{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy import stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "test_id = test['id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calc_variables = [f for f in train.columns if 'calc' in f]\n",
    "train.drop(calc_variables,axis=1,inplace=True)\n",
    "test.drop(calc_variables,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_variables = [f for f in train.columns if 'cat' in f]\n",
    "bin_variables = [f for f in train.columns if 'bin' in f]\n",
    "continuous_variables = [f for f in train.columns if train[f].dtype == 'float64']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate majority and minority classes\n",
    "df_majority = train[train.target==0]\n",
    "df_minority = train[train.target==1]\n",
    " \n",
    "# Downsample majority class\n",
    "n_samples = int(1*len(df_minority))\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=n_samples,     # to match minority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine minority class with downsampled majority class\n",
    "train = pd.concat([df_majority_downsampled, df_minority])\n",
    " \n",
    "# Display new class counts\n",
    "\n",
    "# 1    49\n",
    "# 0    49\n",
    "# Name: balance, dtype: int64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------train data--------------------\n",
      "Variable ps_ind_02_cat has 44 records (0.10%) with missing values\n",
      "Variable ps_ind_04_cat has 36 records (0.08%) with missing values\n",
      "Variable ps_ind_05_cat has 712 records (1.64%) with missing values\n",
      "Variable ps_reg_03 has 6995 records (16.12%) with missing values\n",
      "Variable ps_car_01_cat has 37 records (0.09%) with missing values\n",
      "Variable ps_car_02_cat has 1 records (0.00%) with missing values\n",
      "Variable ps_car_03_cat has 28382 records (65.41%) with missing values\n",
      "Variable ps_car_05_cat has 18181 records (41.90%) with missing values\n",
      "Variable ps_car_07_cat has 1315 records (3.03%) with missing values\n",
      "Variable ps_car_09_cat has 73 records (0.17%) with missing values\n",
      "Variable ps_car_11 has 1 records (0.00%) with missing values\n",
      "Variable ps_car_12 has 1 records (0.00%) with missing values\n",
      "Variable ps_car_14 has 3243 records (7.47%) with missing values\n",
      "In total, there are 13 variables with missing values\n",
      "-----------test data--------------------\n",
      "Variable ps_ind_02_cat has 307 records (0.03%) with missing values\n",
      "Variable ps_ind_04_cat has 145 records (0.02%) with missing values\n",
      "Variable ps_ind_05_cat has 8710 records (0.98%) with missing values\n",
      "Variable ps_reg_03 has 161684 records (18.11%) with missing values\n",
      "Variable ps_car_01_cat has 160 records (0.02%) with missing values\n",
      "Variable ps_car_02_cat has 5 records (0.00%) with missing values\n",
      "Variable ps_car_03_cat has 616911 records (69.10%) with missing values\n",
      "Variable ps_car_05_cat has 400359 records (44.84%) with missing values\n",
      "Variable ps_car_07_cat has 17331 records (1.94%) with missing values\n",
      "Variable ps_car_09_cat has 877 records (0.10%) with missing values\n",
      "Variable ps_car_11 has 1 records (0.00%) with missing values\n",
      "Variable ps_car_14 has 63805 records (7.15%) with missing values\n",
      "In total, there are 12 variables with missing values\n"
     ]
    }
   ],
   "source": [
    "print('-----------train data--------------------')\n",
    "\n",
    "vars_with_missing = []\n",
    "\n",
    "for f in train.columns:\n",
    "    missings = train[train[f] == -1][f].count()\n",
    "    if missings > 0:\n",
    "        vars_with_missing.append(f)\n",
    "        missings_perc = missings/train.shape[0]\n",
    "        \n",
    "        print('Variable {} has {} records ({:.2%}) with missing values'.format(f, missings, missings_perc))\n",
    "        \n",
    "print('In total, there are {} variables with missing values'.format(len(vars_with_missing)))\n",
    "\n",
    "\n",
    "print('-----------test data--------------------')\n",
    "\n",
    "vars_with_missing = []\n",
    "\n",
    "for f in test.columns:\n",
    "    missings = test[test[f] == -1][f].count()\n",
    "    if missings > 0:\n",
    "        vars_with_missing.append(f)\n",
    "        missings_perc = missings/test.shape[0]\n",
    "        \n",
    "        print('Variable {} has {} records ({:.2%}) with missing values'.format(f, missings, missings_perc))\n",
    "        \n",
    "print('In total, there are {} variables with missing values'.format(len(vars_with_missing)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dropping the variables with too many missing values\n",
    "vars_to_drop = ['ps_car_03_cat', 'ps_car_05_cat']\n",
    "train.drop(vars_to_drop, inplace=True, axis=1)\n",
    "test.drop(vars_to_drop, inplace=True, axis=1)\n",
    "\n",
    "cat_variables.remove('ps_car_03_cat')\n",
    "cat_variables.remove('ps_car_05_cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ps_reg_03 (continuous) has missing values for 18% of all records. Replace by the mean.\n",
    "#ps_car_11 (ordinal) has only 5 records with misisng values. Replace by the mode.\n",
    "#ps_car_12 (continuous) has only 1 records with missing value. Replace by the mean.\n",
    "#ps_car_14 (continuous) has missing values for 7% of all records. Replace by the mean.\n",
    "train['ps_reg_03'].replace(to_replace=-1, value=np.mean(train['ps_reg_03'][train['ps_reg_03'] != -1]), inplace=True)\n",
    "train['ps_car_11'].replace(to_replace=-1, value=stats.mode(train['ps_car_11'][train['ps_car_11'] != -1]).mode[0], inplace=True)\n",
    "train['ps_car_12'].replace(to_replace=-1, value=np.mean(train['ps_car_12'][train['ps_car_12'] != -1]), inplace=True)\n",
    "train['ps_car_14'].replace(to_replace=-1, value=np.mean(train['ps_car_14'][train['ps_car_14'] != -1]), inplace=True)\n",
    "\n",
    "test['ps_reg_03'].replace(to_replace=-1, value=np.mean(test['ps_reg_03'][test['ps_reg_03'] != -1]), inplace=True)\n",
    "test['ps_car_11'].replace(to_replace=-1, value=stats.mode(test['ps_car_11'][test['ps_car_11'] != -1]).mode[0], inplace=True)\n",
    "test['ps_car_14'].replace(to_replace=-1, value=np.mean(test['ps_car_14'][test['ps_car_14'] != -1]), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------test data--------------------\n",
      "Variable ps_ind_02_cat has 5 distinct values\n",
      "Variable ps_ind_04_cat has 3 distinct values\n",
      "Variable ps_ind_05_cat has 8 distinct values\n",
      "Variable ps_car_01_cat has 13 distinct values\n",
      "Variable ps_car_02_cat has 3 distinct values\n",
      "Variable ps_car_04_cat has 10 distinct values\n",
      "Variable ps_car_06_cat has 18 distinct values\n",
      "Variable ps_car_07_cat has 3 distinct values\n",
      "Variable ps_car_08_cat has 2 distinct values\n",
      "Variable ps_car_09_cat has 6 distinct values\n",
      "Variable ps_car_10_cat has 3 distinct values\n",
      "Variable ps_car_11_cat has 104 distinct values\n",
      "-----------test data--------------------\n",
      "Variable ps_ind_02_cat has 5 distinct values\n",
      "Variable ps_ind_04_cat has 3 distinct values\n",
      "Variable ps_ind_05_cat has 8 distinct values\n",
      "Variable ps_car_01_cat has 13 distinct values\n",
      "Variable ps_car_02_cat has 3 distinct values\n",
      "Variable ps_car_04_cat has 10 distinct values\n",
      "Variable ps_car_06_cat has 18 distinct values\n",
      "Variable ps_car_07_cat has 3 distinct values\n",
      "Variable ps_car_08_cat has 2 distinct values\n",
      "Variable ps_car_09_cat has 6 distinct values\n",
      "Variable ps_car_10_cat has 3 distinct values\n",
      "Variable ps_car_11_cat has 104 distinct values\n"
     ]
    }
   ],
   "source": [
    "print('-----------test data--------------------')\n",
    "for f in cat_variables:\n",
    "    dist_values = train[f].value_counts().shape[0]\n",
    "    print('Variable {} has {} distinct values'.format(f, dist_values))\n",
    "print('-----------test data--------------------')\n",
    "for f in cat_variables:\n",
    "    dist_values = test[f].value_counts().shape[0]\n",
    "    print('Variable {} has {} distinct values'.format(f, dist_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Script by https://www.kaggle.com/ogrellier\n",
    "# Code: https://www.kaggle.com/ogrellier/python-target-encoding-for-categorical-features\n",
    "def add_noise(series, noise_level):\n",
    "    return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "\n",
    "def target_encode(trn_series=None, \n",
    "                  tst_series=None, \n",
    "                  target=None, \n",
    "                  min_samples_leaf=1, \n",
    "                  smoothing=1,\n",
    "                  noise_level=0):\n",
    "    \"\"\"\n",
    "    Smoothing is computed like in the following paper by Daniele Micci-Barreca\n",
    "    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n",
    "    trn_series : training categorical feature as a pd.Series\n",
    "    tst_series : test categorical feature as a pd.Series\n",
    "    target : target data as a pd.Series\n",
    "    min_samples_leaf (int) : minimum samples to take category average into account\n",
    "    smoothing (int) : smoothing effect to balance categorical average vs prior  \n",
    "    \"\"\" \n",
    "    assert len(trn_series) == len(target)\n",
    "    assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1)\n",
    "    # Compute target mean \n",
    "    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
    "    # Compute smoothing\n",
    "    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
    "    # Apply average function to all target data\n",
    "    prior = target.mean()\n",
    "    # The bigger the count the less full_avg is taken into account\n",
    "    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
    "    # Apply averages to trn and tst series\n",
    "    ft_trn_series = pd.merge(\n",
    "        trn_series.to_frame(trn_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=trn_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_trn_series.index = trn_series.index \n",
    "    ft_tst_series = pd.merge(\n",
    "        tst_series.to_frame(tst_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=tst_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_tst_series.index = tst_series.index\n",
    "    return add_noise(ft_trn_series, noise_level), add_noise(ft_tst_series, noise_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_encoded, test_encoded = target_encode(train[\"ps_car_11_cat\"], \n",
    "                             test[\"ps_car_11_cat\"], \n",
    "                             target=train.target, \n",
    "                             min_samples_leaf=100,\n",
    "                             smoothing=10,\n",
    "                             noise_level=0.01)\n",
    "    \n",
    "train['ps_car_11_cat_te'] = train_encoded\n",
    "train.drop('ps_car_11_cat', axis=1, inplace=True)\n",
    "cat_variables.remove('ps_car_11_cat')\n",
    "test['ps_car_11_cat_te'] = test_encoded\n",
    "test.drop('ps_car_11_cat', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------train data--------------------\n",
      "Before dummification we have 37 variables in train\n",
      "After dummification we have 191 variables in train\n",
      "-----------test data--------------------\n",
      "Before dummification we have 36 variables in train\n",
      "After dummification we have 190 variables in train\n"
     ]
    }
   ],
   "source": [
    "print('-----------train data--------------------')\n",
    "v = cat_variables\n",
    "print('Before dummification we have {} variables in train'.format(train.shape[1]))\n",
    "train = pd.get_dummies(train, columns=v, drop_first=True)\n",
    "print('After dummification we have {} variables in train'.format(train.shape[1]))\n",
    "\n",
    "print('-----------test data--------------------')\n",
    "v = cat_variables\n",
    "print('Before dummification we have {} variables in train'.format(test.shape[1]))\n",
    "test = pd.get_dummies(test, columns=v, drop_first=True)\n",
    "print('After dummification we have {} variables in train'.format(test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------train data--------------------\n",
      "Before creating interactions we have 191 variables in train\n",
      "After creating interactions we have 219 variables in train\n",
      "-----------test data--------------------\n",
      "Before creating interactions we have 190 variables in train\n",
      "After creating interactions we have 218 variables in train\n"
     ]
    }
   ],
   "source": [
    "v = continuous_variables\n",
    "print('-----------train data--------------------')\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\n",
    "interactions = pd.DataFrame(data=poly.fit_transform(train[v]), columns=poly.get_feature_names(v))\n",
    "interactions.drop(v, axis=1, inplace=True)  # Remove the original columns\n",
    "# Concat the interaction variables to the train data\n",
    "print('Before creating interactions we have {} variables in train'.format(train.shape[1]))\n",
    "train = pd.concat([train.reset_index(drop=True), interactions], axis=1)\n",
    "print('After creating interactions we have {} variables in train'.format(train.shape[1]))\n",
    "\n",
    "print('-----------test data--------------------')\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\n",
    "interactions = pd.DataFrame(data=poly.fit_transform(test[v]), columns=poly.get_feature_names(v))\n",
    "interactions.drop(v, axis=1, inplace=True)  # Remove the original columns\n",
    "# Concat the interaction variables to the train data\n",
    "print('Before creating interactions we have {} variables in train'.format(test.shape[1]))\n",
    "test = pd.concat([test.reset_index(drop=True), interactions], axis=1)\n",
    "print('After creating interactions we have {} variables in train'.format(test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) ps_car_11_cat_te               0.023226\n",
      " 2) ps_car_13^2                    0.017592\n",
      " 3) ps_reg_03 ps_car_13            0.017555\n",
      " 4) ps_car_13 ps_car_15            0.017550\n",
      " 5) ps_car_13                      0.017532\n",
      " 6) ps_car_12 ps_car_13            0.017513\n",
      " 7) ps_car_13 ps_car_14            0.017302\n",
      " 8) ps_reg_01 ps_car_13            0.016725\n",
      " 9) ps_reg_03 ps_car_14            0.016053\n",
      "10) ps_car_14 ps_car_15            0.015640\n",
      "11) ps_reg_03 ps_car_12            0.015299\n",
      "12) ps_reg_03 ps_car_15            0.015265\n",
      "13) ps_reg_02 ps_car_13            0.015057\n",
      "14) ps_reg_01 ps_reg_03            0.014630\n",
      "15) ps_reg_01 ps_car_14            0.014524\n",
      "16) ps_car_13 ps_calc_02           0.014299\n",
      "17) ps_car_13 ps_calc_03           0.014296\n",
      "18) ps_car_13 ps_calc_01           0.014212\n",
      "19) ps_car_14 ps_calc_02           0.013749\n",
      "20) ps_reg_03                      0.013686\n",
      "21) ps_reg_03^2                    0.013617\n",
      "22) ps_reg_03 ps_calc_02           0.013608\n",
      "23) ps_car_14 ps_calc_01           0.013586\n",
      "24) ps_car_12 ps_car_14            0.013564\n",
      "25) ps_reg_03 ps_calc_01           0.013556\n",
      "26) ps_reg_03 ps_calc_03           0.013556\n",
      "27) ps_car_14 ps_calc_03           0.013530\n",
      "28) ps_car_14^2                    0.013441\n",
      "29) ps_ind_15                      0.013335\n",
      "30) ps_car_14                      0.013201\n",
      "31) ps_reg_02 ps_car_14            0.013182\n",
      "32) ps_ind_03                      0.012719\n",
      "33) ps_reg_02 ps_reg_03            0.012463\n",
      "34) ps_calc_10                     0.012250\n",
      "35) ps_calc_14                     0.012083\n",
      "36) ps_car_12 ps_car_15            0.011908\n",
      "37) ps_car_15 ps_calc_02           0.011420\n",
      "38) ps_car_15 ps_calc_03           0.011365\n",
      "39) ps_car_15 ps_calc_01           0.011336\n",
      "40) ps_calc_11                     0.011227\n",
      "41) ps_reg_02 ps_car_15            0.011114\n",
      "42) ps_reg_01 ps_car_15            0.011000\n",
      "43) ps_car_12 ps_calc_01           0.010427\n",
      "44) ps_car_12 ps_calc_02           0.010418\n",
      "45) ps_car_12 ps_calc_03           0.010348\n",
      "46) ps_calc_01 ps_calc_02          0.010316\n",
      "47) ps_calc_01 ps_calc_03          0.010310\n",
      "48) ps_calc_02 ps_calc_03          0.010258\n",
      "49) ps_reg_01 ps_car_12            0.009900\n",
      "50) ps_reg_02 ps_car_12            0.009628\n",
      "51) ps_calc_13                     0.009603\n",
      "52) ps_reg_01 ps_calc_02           0.009560\n",
      "53) ps_reg_01 ps_calc_03           0.009524\n",
      "54) ps_reg_01 ps_calc_01           0.009498\n",
      "55) ps_reg_02 ps_calc_02           0.009327\n",
      "56) ps_reg_02 ps_calc_01           0.009251\n",
      "57) ps_reg_02 ps_calc_03           0.009118\n",
      "58) ps_calc_08                     0.008932\n",
      "59) ps_calc_07                     0.008880\n",
      "60) ps_ind_01                      0.008674\n",
      "61) ps_reg_01 ps_reg_02            0.008573\n",
      "62) ps_calc_06                     0.008346\n",
      "63) ps_calc_09                     0.008148\n",
      "64) ps_calc_05                     0.007626\n",
      "65) ps_calc_04                     0.007553\n",
      "66) ps_calc_12                     0.007327\n",
      "67) ps_car_15                      0.006671\n",
      "68) ps_car_15^2                    0.006571\n",
      "69) ps_calc_01                     0.006084\n",
      "70) ps_calc_01^2                   0.006054\n",
      "71) ps_calc_03                     0.006027\n",
      "72) ps_calc_03^2                   0.006004\n",
      "73) ps_calc_02                     0.005979\n",
      "74) ps_calc_02^2                   0.005913\n",
      "75) ps_car_12^2                    0.005831\n",
      "76) ps_car_12                      0.005550\n",
      "77) ps_ind_05_cat_0                0.005205\n",
      "78) ps_reg_02                      0.005035\n",
      "79) ps_reg_02^2                    0.004987\n",
      "80) ps_reg_01                      0.004464\n",
      "81) ps_reg_01^2                    0.004375\n",
      "82) ps_car_11                      0.003774\n",
      "83) ps_ind_17_bin                  0.003768\n",
      "84) ps_ind_06_bin                  0.003325\n",
      "85) ps_ind_16_bin                  0.003245\n",
      "86) ps_car_01_cat_7                0.002713\n",
      "87) ps_ind_07_bin                  0.002630\n",
      "88) ps_calc_17_bin                 0.002613\n",
      "89) ps_calc_16_bin                 0.002581\n",
      "90) ps_calc_19_bin                 0.002540\n",
      "91) ps_calc_18_bin                 0.002458\n",
      "92) ps_ind_04_cat_1                0.002410\n",
      "93) ps_ind_04_cat_0                0.002400\n",
      "94) ps_car_01_cat_11               0.002389\n",
      "95) ps_ind_02_cat_1                0.002310\n",
      "96) ps_car_07_cat_1                0.002306\n",
      "97) ps_car_09_cat_0                0.002301\n",
      "98) ps_car_09_cat_2                0.002291\n",
      "99) ps_calc_20_bin                 0.002141\n",
      "100) ps_ind_02_cat_2                0.002089\n",
      "101) ps_ind_08_bin                  0.002004\n",
      "102) ps_car_06_cat_1                0.001953\n",
      "103) ps_calc_15_bin                 0.001953\n",
      "104) ps_ind_09_bin                  0.001932\n",
      "105) ps_car_06_cat_11               0.001929\n",
      "106) ps_ind_18_bin                  0.001814\n",
      "107) ps_car_01_cat_6                0.001618\n",
      "108) ps_car_07_cat_0                0.001517\n",
      "109) ps_car_06_cat_14               0.001511\n",
      "110) ps_car_01_cat_10               0.001504\n",
      "111) ps_ind_05_cat_6                0.001500\n",
      "112) ps_car_02_cat_1                0.001299\n",
      "113) ps_car_02_cat_0                0.001286\n",
      "114) ps_car_08_cat_1                0.001254\n",
      "115) ps_car_09_cat_1                0.001219\n",
      "116) ps_ind_02_cat_3                0.001194\n",
      "117) ps_car_01_cat_9                0.001118\n",
      "118) ps_car_01_cat_4                0.001112\n",
      "119) ps_car_06_cat_4                0.001062\n",
      "120) ps_ind_05_cat_4                0.001012\n",
      "121) ps_car_04_cat_1                0.000930\n",
      "122) ps_car_06_cat_6                0.000909\n",
      "123) ps_car_06_cat_10               0.000903\n",
      "124) ps_car_01_cat_8                0.000861\n",
      "125) ps_car_04_cat_2                0.000823\n",
      "126) ps_car_01_cat_5                0.000819\n",
      "127) ps_car_06_cat_7                0.000698\n",
      "128) ps_car_06_cat_15               0.000628\n",
      "129) ps_ind_02_cat_4                0.000597\n",
      "130) ps_car_09_cat_3                0.000584\n",
      "131) ps_car_06_cat_9                0.000574\n",
      "132) ps_car_06_cat_3                0.000566\n",
      "133) ps_car_01_cat_3                0.000499\n",
      "134) ps_car_04_cat_8                0.000442\n",
      "135) ps_ind_05_cat_1                0.000438\n",
      "136) ps_ind_05_cat_3                0.000431\n",
      "137) ps_ind_05_cat_2                0.000391\n",
      "138) ps_ind_14                      0.000377\n",
      "139) ps_car_01_cat_0                0.000368\n",
      "140) ps_ind_12_bin                  0.000331\n",
      "141) ps_car_04_cat_9                0.000329\n",
      "142) ps_car_06_cat_16               0.000270\n",
      "143) ps_car_10_cat_1                0.000267\n",
      "144) ps_car_06_cat_13               0.000256\n",
      "145) ps_car_06_cat_17               0.000249\n",
      "146) ps_car_01_cat_2                0.000206\n",
      "147) ps_car_09_cat_4                0.000196\n",
      "148) ps_car_06_cat_12               0.000174\n",
      "149) ps_ind_05_cat_5                0.000140\n",
      "150) ps_car_06_cat_2                0.000101\n",
      "151) ps_car_06_cat_5                0.000083\n",
      "152) ps_car_01_cat_1                0.000080\n",
      "153) ps_ind_11_bin                  0.000073\n",
      "154) ps_car_04_cat_6                0.000071\n",
      "155) ps_car_06_cat_8                0.000060\n",
      "156) ps_car_04_cat_3                0.000042\n",
      "157) ps_ind_13_bin                  0.000032\n",
      "158) ps_car_04_cat_5                0.000027\n",
      "159) ps_car_04_cat_4                0.000014\n",
      "160) ps_ind_10_bin                  0.000011\n",
      "161) ps_car_04_cat_7                0.000009\n",
      "162) ps_car_10_cat_2                0.000008\n"
     ]
    }
   ],
   "source": [
    "X_train = train.drop(['id', 'target'], axis=1)\n",
    "y_train = train['target']\n",
    "\n",
    "feat_labels = X_train.columns\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=500, random_state=0, n_jobs=-1)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "indices = np.argsort(rf.feature_importances_)[::-1]\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30,feat_labels[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features before selection: 162\n",
      "Number of features after selection: 81\n"
     ]
    }
   ],
   "source": [
    "sfm = SelectFromModel(rf, threshold='median', prefit=True)\n",
    "print('Number of features before selection: {}'.format(X_train.shape[1]))\n",
    "n_features = sfm.transform(X_train).shape[1]\n",
    "print('Number of features after selection: {}'.format(n_features))\n",
    "selected_vars = list(feat_labels[sfm.get_support()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train[selected_vars + ['target']]\n",
    "test = test[selected_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = shuffle(train).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gini(actual, pred, cmpcol = 0, sortcol = 1):\n",
    "     assert( len(actual) == len(pred) )\n",
    "     all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n",
    "     all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n",
    "     totalLosses = all[:,0].sum()\n",
    "     giniSum = all[:,0].cumsum().sum() / totalLosses\n",
    " \n",
    "     giniSum -= (len(actual) + 1) / 2.\n",
    "     return giniSum / len(actual)\n",
    "def gini_normalized(a, p):\n",
    "     return gini(a, p) / gini(a, a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = train.drop(['id','target'],axis=1)\n",
    "Y_train = train['target']\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(test.drop('id',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_neighbors = [300,500,600,700,800,1000,1200]\n",
    "kf = KFold(n_splits=5,random_state=1000)\n",
    "gini_results = {}\n",
    "auc_results={}\n",
    "\n",
    "for n_neighbor in n_neighbors:\n",
    "    knn  = KNeighborsClassifier(n_neighbors = n_neighbor,n_jobs = -1)\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        knn.fit(X_train[train_index],Y_train[train_index])\n",
    "        predict = knn.predict_proba(X_train[test_index])[:,1]\n",
    "        auc = roc_auc_score(Y_train[test_index], predict)\n",
    "        gini_score = gini_normalized(Y_train[test_index], predict)\n",
    "        gini_results.setdefault(n_neighbor,[]).append(gini_score)\n",
    "        auc_results.setdefault(n_neighbor,[]).append(auc)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>300</th>\n",
       "      <th>500</th>\n",
       "      <th>600</th>\n",
       "      <th>700</th>\n",
       "      <th>800</th>\n",
       "      <th>1000</th>\n",
       "      <th>1200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.594381</td>\n",
       "      <td>0.595479</td>\n",
       "      <td>0.595496</td>\n",
       "      <td>0.595976</td>\n",
       "      <td>0.595706</td>\n",
       "      <td>0.595146</td>\n",
       "      <td>0.594967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.005818</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>0.006162</td>\n",
       "      <td>0.006202</td>\n",
       "      <td>0.006847</td>\n",
       "      <td>0.006581</td>\n",
       "      <td>0.006477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.589047</td>\n",
       "      <td>0.589348</td>\n",
       "      <td>0.587704</td>\n",
       "      <td>0.587593</td>\n",
       "      <td>0.586601</td>\n",
       "      <td>0.586943</td>\n",
       "      <td>0.588274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.589243</td>\n",
       "      <td>0.590963</td>\n",
       "      <td>0.592607</td>\n",
       "      <td>0.593492</td>\n",
       "      <td>0.592937</td>\n",
       "      <td>0.592500</td>\n",
       "      <td>0.591150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.592610</td>\n",
       "      <td>0.594572</td>\n",
       "      <td>0.594030</td>\n",
       "      <td>0.594816</td>\n",
       "      <td>0.594068</td>\n",
       "      <td>0.592506</td>\n",
       "      <td>0.591676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.599393</td>\n",
       "      <td>0.599885</td>\n",
       "      <td>0.599712</td>\n",
       "      <td>0.600614</td>\n",
       "      <td>0.601240</td>\n",
       "      <td>0.601169</td>\n",
       "      <td>0.600770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.601612</td>\n",
       "      <td>0.602629</td>\n",
       "      <td>0.603427</td>\n",
       "      <td>0.603362</td>\n",
       "      <td>0.603686</td>\n",
       "      <td>0.602610</td>\n",
       "      <td>0.602963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           300       500       600       700       800       1000      1200\n",
       "count  5.000000  5.000000  5.000000  5.000000  5.000000  5.000000  5.000000\n",
       "mean   0.594381  0.595479  0.595496  0.595976  0.595706  0.595146  0.594967\n",
       "std    0.005818  0.005686  0.006162  0.006202  0.006847  0.006581  0.006477\n",
       "min    0.589047  0.589348  0.587704  0.587593  0.586601  0.586943  0.588274\n",
       "25%    0.589243  0.590963  0.592607  0.593492  0.592937  0.592500  0.591150\n",
       "50%    0.592610  0.594572  0.594030  0.594816  0.594068  0.592506  0.591676\n",
       "75%    0.599393  0.599885  0.599712  0.600614  0.601240  0.601169  0.600770\n",
       "max    0.601612  0.602629  0.603427  0.603362  0.603686  0.602610  0.602963"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(auc_results).describe()\n",
    "#700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_neighbors = [700,720,740,760,780,800]\n",
    "kf = KFold(n_splits=5,random_state=1000)\n",
    "gini_results = {}\n",
    "auc_results={}\n",
    "\n",
    "for n_neighbor in n_neighbors:\n",
    "    knn  = KNeighborsClassifier(n_neighbors = n_neighbor,n_jobs = -1)\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        knn.fit(X_train[train_index],Y_train[train_index])\n",
    "        predict = knn.predict_proba(X_train[test_index])[:,1]\n",
    "        auc = roc_auc_score(Y_train[test_index], predict)\n",
    "        gini_score = gini_normalized(Y_train[test_index], predict)\n",
    "        gini_results.setdefault(n_neighbor,[]).append(gini_score)\n",
    "        auc_results.setdefault(n_neighbor,[]).append(auc)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>700</th>\n",
       "      <th>720</th>\n",
       "      <th>740</th>\n",
       "      <th>760</th>\n",
       "      <th>780</th>\n",
       "      <th>800</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.595976</td>\n",
       "      <td>0.595962</td>\n",
       "      <td>0.595978</td>\n",
       "      <td>0.595893</td>\n",
       "      <td>0.595818</td>\n",
       "      <td>0.595706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.006202</td>\n",
       "      <td>0.006602</td>\n",
       "      <td>0.006577</td>\n",
       "      <td>0.006729</td>\n",
       "      <td>0.006647</td>\n",
       "      <td>0.006847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.587593</td>\n",
       "      <td>0.587054</td>\n",
       "      <td>0.587152</td>\n",
       "      <td>0.586476</td>\n",
       "      <td>0.586759</td>\n",
       "      <td>0.586601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.593492</td>\n",
       "      <td>0.593564</td>\n",
       "      <td>0.593496</td>\n",
       "      <td>0.593800</td>\n",
       "      <td>0.593415</td>\n",
       "      <td>0.592937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.594816</td>\n",
       "      <td>0.594393</td>\n",
       "      <td>0.594396</td>\n",
       "      <td>0.594611</td>\n",
       "      <td>0.594451</td>\n",
       "      <td>0.594068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.600614</td>\n",
       "      <td>0.601000</td>\n",
       "      <td>0.601124</td>\n",
       "      <td>0.600779</td>\n",
       "      <td>0.600696</td>\n",
       "      <td>0.601240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.603362</td>\n",
       "      <td>0.603799</td>\n",
       "      <td>0.603724</td>\n",
       "      <td>0.603801</td>\n",
       "      <td>0.603770</td>\n",
       "      <td>0.603686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            700       720       740       760       780       800\n",
       "count  5.000000  5.000000  5.000000  5.000000  5.000000  5.000000\n",
       "mean   0.595976  0.595962  0.595978  0.595893  0.595818  0.595706\n",
       "std    0.006202  0.006602  0.006577  0.006729  0.006647  0.006847\n",
       "min    0.587593  0.587054  0.587152  0.586476  0.586759  0.586601\n",
       "25%    0.593492  0.593564  0.593496  0.593800  0.593415  0.592937\n",
       "50%    0.594816  0.594393  0.594396  0.594611  0.594451  0.594068\n",
       "75%    0.600614  0.601000  0.601124  0.600779  0.600696  0.601240\n",
       "max    0.603362  0.603799  0.603724  0.603801  0.603770  0.603686"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(auc_results).describe()\n",
    "#700"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train['target'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn  = KNeighborsClassifier(n_neighbors = 700,n_jobs = -1,algorithm='kd_tree')\n",
    "knn.fit(X_train,train['target'])\n",
    "predict = knn.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['id'] = test_id\n",
    "sub['target'] = predict\n",
    "sub.to_csv('knn_submit.csv', float_format='%.6f', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((892816, 58), (892816,))"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape,predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for f in train.columns:\n",
    "    # Defining the role\n",
    "    if f == 'target':\n",
    "        role = 'target'\n",
    "    elif f == 'id':\n",
    "        role = 'id'\n",
    "    else:\n",
    "        role = 'input'\n",
    "         \n",
    "    # Defining the level\n",
    "    if 'bin' in f or f == 'target':\n",
    "        level = 'binary'\n",
    "    elif 'cat' in f or f == 'id':\n",
    "        level = 'nominal'\n",
    "    elif train[f].dtype == float:\n",
    "        level = 'interval'\n",
    "    elif train[f].dtype == int:\n",
    "        level = 'ordinal'\n",
    "        \n",
    "    # Initialize keep to True for all variables except for id\n",
    "    \n",
    "    # Defining the data type \n",
    "    dtype = train[f].dtype\n",
    "    \n",
    "    # Creating a Dict that contains all the metadata for the variable\n",
    "    f_dict = {\n",
    "        'varname': f,\n",
    "        'role': role,\n",
    "        'level': level,\n",
    "        'keep': keep,\n",
    "        'dtype': dtype\n",
    "    }\n",
    "    data.append(f_dict)\n",
    "    \n",
    "meta = pd.DataFrame(data, columns=['varname', 'role', 'level',  'dtype'])\n",
    "meta.set_index('varname', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta.T.to_csv('asdf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
